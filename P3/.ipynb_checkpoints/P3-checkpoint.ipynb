{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "realistic-harrison",
   "metadata": {},
   "source": [
    "# SDND Project 3 - Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-corrections",
   "metadata": {},
   "source": [
    "## 0. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civilian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "closing-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"traffic-signs-data/train.p\"\n",
    "validation_file = \"traffic-signs-data/valid.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-guyana",
   "metadata": {},
   "source": [
    "## 1. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "biblical-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "anticipated-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n",
      "\n",
      "0 - Speed limit (20km/h)\n",
      "\n",
      "1 - Speed limit (30km/h)\n",
      "\n",
      "2 - Speed limit (50km/h)\n",
      "\n",
      "3 - Speed limit (60km/h)\n",
      "\n",
      "4 - Speed limit (70km/h)\n",
      "\n",
      "5 - Speed limit (80km/h)\n",
      "\n",
      "6 - End of speed limit (80km/h)\n",
      "\n",
      "7 - Speed limit (100km/h)\n",
      "\n",
      "8 - Speed limit (120km/h)\n",
      "\n",
      "9 - No passing\n",
      "\n",
      "10 - No passing for vehicles over 3.5 metric tons\n",
      "\n",
      "11 - Right-of-way at the next intersection\n",
      "\n",
      "12 - Priority road\n",
      "\n",
      "13 - Yield\n",
      "\n",
      "14 - Stop\n",
      "\n",
      "15 - No vehicles\n",
      "\n",
      "16 - Vehicles over 3.5 metric tons prohibited\n",
      "\n",
      "17 - No entry\n",
      "\n",
      "18 - General caution\n",
      "\n",
      "19 - Dangerous curve to the left\n",
      "\n",
      "20 - Dangerous curve to the right\n",
      "\n",
      "21 - Double curve\n",
      "\n",
      "22 - Bumpy road\n",
      "\n",
      "23 - Slippery road\n",
      "\n",
      "24 - Road narrows on the right\n",
      "\n",
      "25 - Road work\n",
      "\n",
      "26 - Traffic signals\n",
      "\n",
      "27 - Pedestrians\n",
      "\n",
      "28 - Children crossing\n",
      "\n",
      "29 - Bicycles crossing\n",
      "\n",
      "30 - Beware of ice/snow\n",
      "\n",
      "31 - Wild animals crossing\n",
      "\n",
      "32 - End of all speed and passing limits\n",
      "\n",
      "33 - Turn right ahead\n",
      "\n",
      "34 - Turn left ahead\n",
      "\n",
      "35 - Ahead only\n",
      "\n",
      "36 - Go straight or right\n",
      "\n",
      "37 - Go straight or left\n",
      "\n",
      "38 - Keep right\n",
      "\n",
      "39 - Keep left\n",
      "\n",
      "40 - Roundabout mandatory\n",
      "\n",
      "41 - End of no passing\n",
      "\n",
      "42 - End of no passing by vehicles over 3.5 metric tons\n"
     ]
    }
   ],
   "source": [
    "# -- Number of samples -- #\n",
    "n_train = len(X_train)   \n",
    "n_valid = len(X_valid)   \n",
    "n_test = len(X_test)     \n",
    "\n",
    "# -- Shape of a traffic sign image -- # \n",
    "image_shape = X_train[0].shape        \n",
    "\n",
    "# -- Number of classes -- #\n",
    "n_classes = len(set(y_train)) \n",
    "\n",
    "# -- Labels & names -- #\n",
    "sign_name_file = pd.read_csv('signnames.csv')\n",
    "sign_name = sign_name_file.to_dict(orient='index')\n",
    "sign_name = {key : val['SignName'] for key, val in sign_name.items()}\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "\n",
    "for i in range(len(sign_name)):\n",
    "    print()\n",
    "    print(i, \"-\", sign_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-munich",
   "metadata": {},
   "source": [
    "### Exploratory Visualization of Dataset - TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "talented-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-plenty",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-scale",
   "metadata": {},
   "source": [
    "### 2.1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informative-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augment_Images(X, y):\n",
    "    \n",
    "    augmented = []\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        seed = (i, 0)\n",
    "        image = tf.cast(X[i], tf.float32)\n",
    "        image = (image / 255.0)\n",
    "        \n",
    "        flag = random.randint(0, 9)\n",
    "        \n",
    "        if (flag <= 5):\n",
    "            result = (image * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 6):\n",
    "            flip_h = tf.image.flip_left_right(image)\n",
    "            result = (flip_h * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 7):\n",
    "            flip_v = tf.image.flip_up_down(image)\n",
    "            result = (flip_v * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 8):\n",
    "            bright = tf.image.stateless_random_brightness(image, 0.1, seed)\n",
    "            result = (bright * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 9):\n",
    "            contrast = tf.image.stateless_random_contrast(image, 0.9, 1.1, seed)\n",
    "            result = (contrast * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "    augmented_nm, y = Normalize_Images(augmented, y)\n",
    "        \n",
    "    return augmented_nm, y\n",
    "\n",
    "def Normalize_Images(X, y):\n",
    "    \n",
    "    normalized = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        image = tf.cast(X[i], tf.float32)\n",
    "#         image = image / 255.0\n",
    "#         image = tf.image.rgb_to_grayscale(image)\n",
    "        image = (image - 128.0) / 128.0\n",
    "    \n",
    "        normalized.append(image)\n",
    "    \n",
    "    return normalized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dangerous-candle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-0] Preprocessing Start!\n",
      "[1-1] Shuffle Done!\n",
      "[1-2] Training Data Augmented!\n",
      "[1-3] Datasets Normalized!\n",
      "[1-F] Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"[1-0] Preprocessing Start!\")\n",
    "\n",
    "# -- 2.1.1. Shuffle the datasets. -- # \n",
    "X_train_sf, y_train_sf = shuffle(X_train, y_train)\n",
    "X_valid_sf, y_valid_sf = shuffle(X_valid, y_valid)\n",
    "X_test_sf, y_test_sf = shuffle(X_test, y_test)\n",
    "print(\"[1-1] Shuffle Done!\")\n",
    "\n",
    "# -- 2.1.2. Data augmentation & normalization. -- #\n",
    "X_train_pp, y_train_pp = Augment_Images(X_train_sf, y_train_sf)\n",
    "print(\"[1-2] Training Data Augmented!\")\n",
    "\n",
    "X_train_nm, y_train_nm = Normalize_Images(X_train_sf, y_train_sf)\n",
    "X_valid_nm, y_valid_nm = Normalize_Images(X_valid_sf, y_valid_sf)\n",
    "X_test_nm, y_test_nm = Normalize_Images(X_test_sf, y_test_sf)\n",
    "print(\"[1-3] Datasets Normalized!\")\n",
    "\n",
    "print(\"[1-F] Preprocessing Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-facility",
   "metadata": {},
   "source": [
    "### 2.2. LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "major-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "leading-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = X_train_pp[0].shape[2]\n",
    "\n",
    "def LeNet5(X):\n",
    "    \n",
    "    # - Random W & b. - # \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    epsilon = 0.001\n",
    "    \n",
    "    # - L1: Conv. Input: 32x32x3. Output: 28x28x6. - #\n",
    "    conv1_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, channels, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.add(tf.nn.conv2d(X, conv1_W, strides=[1, 1, 1, 1], padding='VALID'), conv1_b)\n",
    "    conv1   = tf.nn.relu(conv1)\n",
    "    # -- L1 Batch normalization. \n",
    "    mean_1, var_1 = v1.nn.moments(conv1, [0])\n",
    "    scale_1 = tf.Variable(tf.ones([28, 28, 6]))\n",
    "    offset_1 = tf.Variable(tf.zeros([28, 28, 6]))\n",
    "    conv1 = v1.nn.batch_normalization(conv1, mean_1, var_1, offset_1, scale_1, epsilon)\n",
    "    # -- L1 Pooling. Input: 28x28x6. Output: 14x14x6. \n",
    "    conv1   = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # - L2: Conv. Input: 14x14x6. Output: 10x10x16. - # \n",
    "    conv2_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.add(tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID'), conv2_b)\n",
    "    conv2   = tf.nn.relu(conv2)\n",
    "    # -- L2 Batch normalization. \n",
    "    mean_2, var_2 = v1.nn.moments(conv2, [0])\n",
    "    scale_2 = tf.Variable(tf.ones([10, 10, 16]))\n",
    "    offset_2 = tf.Variable(tf.zeros([10, 10, 16]))\n",
    "    conv2 = v1.nn.batch_normalization(conv2, mean_2, var_2, offset_2, scale_2, epsilon)\n",
    "    # -- L2 Pooling. Input: 10x10x16. Output: 5x5x16. \n",
    "    conv2   = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    # -- L2 Flatten. Input: 5x5x16. Output: 400.\n",
    "    fc0     = v1.layers.flatten(conv2)   \n",
    "    \n",
    "    # - L3: Fully connected. Input: 400. Output: 120. - #\n",
    "    fc1_W   = tf.Variable(tf.random.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b   = tf.Variable(tf.zeros(120))\n",
    "    fc1     = tf.add(tf.matmul(fc0, fc1_W), fc1_b)\n",
    "    fc1     = tf.nn.relu(fc1)\n",
    "    # -- L3. Batch normalization. \n",
    "    mean_3, var_3 = v1.nn.moments(fc1, [0])\n",
    "    scale_3 = tf.Variable(tf.ones([120]))\n",
    "    offset_3 = tf.Variable(tf.zeros([120]))\n",
    "    fc1 = v1.nn.batch_normalization(fc1, mean_3, var_3, offset_3, scale_3, epsilon)\n",
    "    # -- L3. Dropout. \n",
    "    fc1     = v1.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # - L4: Fully connected. Input: 120. Output: 84. - #\n",
    "    fc2_W   = tf.Variable(tf.random.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b   = tf.Variable(tf.zeros(84))\n",
    "    fc2     = tf.add(tf.matmul(fc1, fc2_W), fc2_b)\n",
    "    fc2     = tf.nn.relu(fc2)\n",
    "    # -- L4. Batch normalization. \n",
    "    mean_4, var_4 = v1.nn.moments(fc2, [0])\n",
    "    scale_4 = tf.Variable(tf.ones([84]))\n",
    "    offset_4 = tf.Variable(tf.zeros([84]))\n",
    "    fc2 = v1.nn.batch_normalization(fc2, mean_4, var_4, offset_4, scale_4, epsilon)\n",
    "    # -- L4. Dropout. \n",
    "    fc2     = v1.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # - L5: Fully connected. Input: 84. Output: 43. - # \n",
    "    fc3_W   = tf.Variable(tf.random.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b   = tf.Variable(tf.zeros(43))\n",
    "    fc3     = tf.add(tf.matmul(fc2, fc3_W), fc3_b)\n",
    "    logits  = fc3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-dover",
   "metadata": {},
   "source": [
    "### 2.3. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "ETA = 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "photographic-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "D:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "G = v1.Graph()\n",
    "\n",
    "with G.as_default():\n",
    "    \n",
    "    x = v1.placeholder(tf.float32, (None, 32, 32, channels))\n",
    "    y = v1.placeholder(tf.int32, (None))\n",
    "    one_hot_y = v1.one_hot(y, 43)\n",
    "    keep_prob = v1.placeholder(v1.float32)\n",
    "    \n",
    "    logits = LeNet5(x)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = v1.train.AdamOptimizer(learning_rate = ETA, beta1=0.9, beta2=0.999)\n",
    "    training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    saver = v1.train.Saver()\n",
    "    \n",
    "    def Evaluate_Model(X_data, y_data):\n",
    "        \n",
    "        num_examples = len(X_data)\n",
    "        total_accuracy = 0\n",
    "        sess = v1.get_default_session()\n",
    "        \n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            \n",
    "            batch_x, batch_y = X_data[offset : offset+BATCH_SIZE], y_data[offset : offset+BATCH_SIZE]\n",
    "            accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1})\n",
    "            total_accuracy += (accuracy * len(batch_x))\n",
    "            \n",
    "        return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "therapeutic-vegetable",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.798\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.876\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.908\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.905\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.897\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.904\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.917\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 46 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 47 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 48 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 49 ...\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "EPOCH 50 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 51 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 52 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 53 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 54 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 55 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 56 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 57 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 58 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 59 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 60 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 61 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 62 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 63 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 64 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 65 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 66 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 67 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 68 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 69 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 70 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 71 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 72 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 73 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 74 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 75 ...\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "EPOCH 76 ...\n",
      "Validation Accuracy = 0.915\n",
      "\n",
      "EPOCH 77 ...\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "EPOCH 78 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 79 ...\n",
      "Validation Accuracy = 0.920\n",
      "\n",
      "EPOCH 80 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 81 ...\n",
      "Validation Accuracy = 0.924\n",
      "\n",
      "EPOCH 82 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 83 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 84 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 85 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 86 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 87 ...\n",
      "Validation Accuracy = 0.933\n",
      "\n",
      "EPOCH 88 ...\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "EPOCH 89 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 90 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0b99ab98e9af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluate_Model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid_nm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid_nm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 968\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1158\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mD:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    sess.run(v1.global_variables_initializer())\n",
    "    num_examples = len(X_train_pp)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    v1.set_random_seed(123456)\n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        X_train, y_train = shuffle(X_train_pp, y_train_pp)\n",
    "        \n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            \n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "            \n",
    "        validation_accuracy = Evaluate_Model(X_valid_nm, y_valid_nm)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "metallic-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.925\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    test_accuracy = Evaluate_Model(X_test_nm, y_test_nm)\n",
    "    \n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "hindu-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Validation Accuracy = 0.936\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    valid_accuracy = Evaluate_Model(X_valid_nm, y_valid_nm)\n",
    "    \n",
    "    print(\"Validation Accuracy = {:.3f}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sapphire-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Training Accuracy = 0.995\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    train_accuracy = Evaluate_Model(X_train_nm, y_train_nm)\n",
    "    \n",
    "    print(\"Training Accuracy = {:.3f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-bradley",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Test Model on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-theme",
   "metadata": {},
   "source": [
    "### 3.1. Load and plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-exemption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "super-mileage",
   "metadata": {},
   "source": [
    "### 3.2. Predict the sign type for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-smile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exciting-locator",
   "metadata": {},
   "source": [
    "### 3.3. 5 Top Softmax probabilities for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-congress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
