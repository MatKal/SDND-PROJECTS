{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "realistic-harrison",
   "metadata": {},
   "source": [
    "# SDND Project 3 - Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-corrections",
   "metadata": {},
   "source": [
    "## 0. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closing-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"traffic-signs-data/train.p\"\n",
    "validation_file = \"traffic-signs-data/valid.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-guyana",
   "metadata": {},
   "source": [
    "## 1. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anticipated-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# -- Number of samples -- #\n",
    "n_train = len(X_train)   \n",
    "n_valid = len(X_valid)   \n",
    "n_test = len(X_test)     \n",
    "\n",
    "# -- Shape of a traffic sign image -- # \n",
    "image_shape = X_train[0].shape        \n",
    "\n",
    "# -- Number of classes -- #\n",
    "n_classes = len(set(y_train)) \n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-munich",
   "metadata": {},
   "source": [
    "### Exploratory Visualization of Dataset - TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-plenty",
   "metadata": {},
   "source": [
    "## 2. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-scale",
   "metadata": {},
   "source": [
    "### 2.1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informative-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hybrid-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Images(X, y):\n",
    "    print(\"[1-0] Preprocessing Start!\")\n",
    "    \n",
    "    augmented = []\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        seed = (i, 0)\n",
    "        image = tf.cast(X[i], tf.float32)\n",
    "        image = (image / 255.0)\n",
    "        \n",
    "        flag = random.randint(0, 9)\n",
    "        \n",
    "        if (flag <= 5):\n",
    "            result = ((image * 255) - 128) / 128\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 6):\n",
    "            flip_h = tf.image.flip_left_right(image)\n",
    "            result = ((flip_h * 255) - 128) / 128\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 7):\n",
    "            flip_v = tf.image.flip_up_down(image)\n",
    "            result = ((flip_v * 255) - 128) / 128\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 8):\n",
    "            bright = tf.image.stateless_random_brightness(image, 0.1, seed)\n",
    "            result = ((bright * 255) - 128) / 128\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 9):\n",
    "            contrast = tf.image.stateless_random_contrast(image, 0.9, 1.1, seed)\n",
    "            result = ((contrast * 255) - 128) / 128\n",
    "            augmented.append(result)\n",
    "\n",
    "    print(\"[1-1] Preprocessing Done!\")\n",
    "    return augmented, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dangerous-candle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-0] Preprocessing Start!\n",
      "[1-1] Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "# -- 2.1.1. Shuffle the datasets. -- # \n",
    "X_train_sf, y_train_sf = shuffle(X_train, y_train)\n",
    "X_valid_sf, y_valid_sf = shuffle(X_valid, y_valid)\n",
    "X_test_sf, y_test_sf = shuffle(X_test, y_test)\n",
    "\n",
    "# -- 2.1.2. Data augmentation & normalization. -- #\n",
    "X_train_pp, y_train_pp = Preprocess_Images(X_train_sf, y_train_sf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "premier-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst1 = X_train_pp[12]*128+128\n",
    "# plt.imshow(np.uint8(tst1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-facility",
   "metadata": {},
   "source": [
    "### 2.2. LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "leading-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as v1\n",
    "\n",
    "def LeNet5(X):\n",
    "    \n",
    "    # - Random W & b. - # \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # - L1: Conv. Input: 32x32x3. Output: 28x28x6. - #\n",
    "    conv1_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(X, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1   = tf.nn.relu(conv1)\n",
    "    \n",
    "    # - L1 Pooling. Input: 28x28x6. Output: 14x14x6. - #\n",
    "    conv1   = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # - L2: Conv. Input: 14x14x6. Output: 10x10x16. - # \n",
    "    conv2_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2   = tf.nn.relu(conv2)\n",
    "    \n",
    "    # - L2 Pooling. Input: 10x10x16. Output: 5x5x16. - # \n",
    "    conv2   = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    # - L2 Flatten. Input: 5x5x16. Output: 400. - #\n",
    "    fc0     = v1.layers.flatten(conv2)\n",
    "    \n",
    "    # - L3: Fully connected. Input: 400. Output: 120. - #\n",
    "    fc1_W   = tf.Variable(tf.random.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b   = tf.Variable(tf.zeros(120))\n",
    "    fc1     = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    fc1     = tf.nn.relu(fc1)\n",
    "    \n",
    "    # - L4: Fully connected. Input: 120. Output: 84. - #\n",
    "    fc2_W   = tf.Variable(tf.random.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b   = tf.Variable(tf.zeros(84))\n",
    "    fc2     = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    fc2     = tf.nn.relu(fc2)\n",
    "    \n",
    "    # - L5: Fully connected. Input: 84. Output: 43. - # \n",
    "    fc3_W   = tf.Variable(tf.random.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b   = tf.Variable(tf.zeros(43))\n",
    "    fc3     = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    logits  = fc3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "controlled-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "ETA = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "therapeutic-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.743\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.859\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.843\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.859\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.869\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.859\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.880\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.869\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.878\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.871\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.882\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.872\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.850\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.895\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.855\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.890\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.894\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.854\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.878\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.884\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.882\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.892\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.788\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "g = v1.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    \n",
    "    x = v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "    y = v1.placeholder(tf.int32, (None))\n",
    "    one_hot_y = v1.one_hot(y, 43)\n",
    "    \n",
    "    \n",
    "    \n",
    "    logits = LeNet5(x)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = v1.train.AdamOptimizer(learning_rate = ETA)\n",
    "    training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    saver = v1.train.Saver()\n",
    "    \n",
    "    def evaluate(X_data, y_data):\n",
    "        num_examples = len(X_data)\n",
    "        total_accuracy = 0\n",
    "        sess = v1.get_default_session()\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "            accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            total_accuracy += (accuracy * len(batch_x))\n",
    "        return total_accuracy / num_examples\n",
    "    \n",
    "    \n",
    "with v1.Session(graph=g) as sess:\n",
    "    \n",
    "    sess.run(v1.global_variables_initializer())\n",
    "    num_examples = len(X_train_pp)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train_pp, y_train_pp)##\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid_sf, y_valid_sf)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "metallic-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.820\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=g) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test_sf, y_test_sf)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
