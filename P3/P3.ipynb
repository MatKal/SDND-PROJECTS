{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "realistic-harrison",
   "metadata": {},
   "source": [
    "# SDND Project 3 - Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-corrections",
   "metadata": {},
   "source": [
    "## 0. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "closing-politics",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"traffic-signs-data/train.p\"\n",
    "validation_file = \"traffic-signs-data/valid.p\"\n",
    "testing_file = \"traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-guyana",
   "metadata": {},
   "source": [
    "## 1. Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anticipated-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "# -- Number of samples -- #\n",
    "n_train = len(X_train)   \n",
    "n_valid = len(X_valid)   \n",
    "n_test = len(X_test)     \n",
    "\n",
    "# -- Shape of a traffic sign image -- # \n",
    "image_shape = X_train[0].shape        \n",
    "\n",
    "# -- Number of classes -- #\n",
    "n_classes = len(set(y_train)) \n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_valid)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-munich",
   "metadata": {},
   "source": [
    "### Exploratory Visualization of Dataset - TBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFgAAABYCAYAAABxlTA0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUhklEQVR4nO2cS6hty1WGv1FVc669z7nX3Hu5SQhJjGLS0FYEUcFO8AFiJ9pQjCBpCBFMUMGGwZZNG2pXiBiwIYigYBoBkaANOxINQY1BDaJ56jUh93H2WnPWa9gYVXPOtc9jn9feZxv3OOyz1prPmn+N+sejRk1RVW7k8sQ96wZ8q8sNwJcsNwBfstwAfMlyA/Alyw3AlyxPBLCI/LiI/IuIfEFEPvq0GvWtJPK4frCIeOBfgR8Dvgx8GviAqv7z02ve/30JT3Du9wNfUNV/BxCRPwbeD9wX4HEc9fT0dN0gd3052rRuBem/5PhoudexbePyuW5EpG0RQaTvc7ZbZNmHbK7dj12uIZtj4ZVXXuH1117fNmGRJwH47cCXNr+/DPzA+YNE5EPAhwBOT09534/+MNIeSBDEOUQE5x3eebzzBO9wIvj2UN4LThzOCcF72+ekHQPO2fFOHOLa8c7hncP7Aecc4jzOgXMQvF/2iTh8GHDe258LiHPgPM4JLji8d3YP7xHncME+xTmcOD78S798X5CeBOB79dhdfKOqHwM+BvDym1/Wl15+2R5eDFgJHuccu92OcRzZ7XachIHgPUMDYhwDIQSC94zjgPeOXbCHDs4+RYQQQgPM4b11QhhOEPHWqU5xTvFiHYIKLNrsEHEgDhBUa1d6EFAUVUUFKtq2AdU67DIA/jLwzs3vdwBffdAJu90J7373u/HOr433psW73Qm7ccfJyQm3xpHBe0LXUmca6Tafg+9auw5fcb59BxFFBJwfF+AERaTQYEW0D/m2X4RukkTN/isG6GKrFFw7ThrQck9yMHkSgD8NvEdEvhP4CvCzwM896IRhHHn7O95JcI6mE6ijAXzKbrfj1ukpt8eRMQS82EM4tA0NWf73zmhmcYOkc6f9VK1ABTGtth2KUKBWQ04b0F0DRZCqDURQFQqgtdj5qna8SGs9S2fdTx4bYFXNIvIR4C8AD3xcVT930XmyAaDWghY1rRxGRuDUe058aPQABoqCNpDVNNQ5j4j2tjSNarzuBUWo6lrT+p7awDNtxjV4nDO8FWiajzi0QqmKOt9QrIi2ntFN2x4gT6LBqOongU8+whmUnME5aslUrYCC92ipUO0BFqBE27emK6p3eQid9vux69Y+dvvVaBorjSpkOUZZoTJPoXWc9OvQrtVpQs9p7f1BfiKAH1VKLrz26qs4EWqtqFbGYWAYBgbxzM4ThxN2ftfowYDTFZ0GDs0InX8w+1216ZVstxuES+ctW9c/2lEABaj9dHHbvlyvqYDWB+F7tQBrrcyHQ1NGG9Y2+pU5BEKITGNkHBIgBNUF4E4trgHvNn7qoqVdK3WrX13rzgOxsmfV4602+lv7pI8g0KqoVuNkNQWhFB4UrF0pwLVWDvszSq3NajtQKKUap7qADyPjMLbjATFD6JpR63bMw+JBmIbJasy00YBu+VtXrBdjaN5AB1REVyO5Nav9oFrRWqklo9WA1pqvD8CglJTJWoHuOs2knCm1kFImpYzWwunJCbvRI04Q3wFs1ACMLXjwziNuAHHMcaLWSqmFcQiMY+BkN1hQ0QBeAEWpjX9rJwYB57q21lXhW4eVUqilmP1onzklaq13PWmXq6UINS3WqqiYgcuNj+mOPDAOnlozpYxL5NRtVi3mx2YfcM7jfUA8II437uzJ7aFPTnecnu4QL4whNP5VqOZ+KU2TYaEgAWrVhcJWlW9tL4VaiwGdM6VkYozXSINV0bK6VqDklBARcs7EOTFNM3GeGIbA6ektfAgMQ2hDVqk5mavlPCEEhmEEFygKX/zSV5jnmRhnTp875dbzt3jXt7+L55+7zYvDgFRFc6aoUhXEBYsqg8e1cNhMmzY/WhfvQ6uSk2lunA+kGElxYn84kHO+7yNfMUWwaCl0nhNUZVEWBOY4U2pGEbw3IPuD11IAxUkHOFERcqm8+s1vME0T07TndrxNzM/zwosv2qg4OUG0AVwqVZUwjDjvGRlx1aJEZAW4BxWNRyjFtDflTEqRGKPRkl4XigBKrW1oWqNUxX53rwdQLTgnTFNsobJFfmbirSd6AmYYPDEmYoy88tX/ZL8/443XX+P5l17gTS+9wG53wtm3nVHe9IIFCbVQSqbWyq1btwhh4PT0Vgu7QVxZWivi8C4sbl2MiZwz0zST5ok479nv71wfDkaVqrryW3fgF3+tGgcCtYplv4DanPxunBDwxeEEchLiYWKeJ+KdO6T9nnI4sH9VqDlzeusFpkOErM21q9C0M9XKEAZSqQTnCE4IwQxd9yEEZ8kihJISJRvvphiZYyTGGb02ALOhCNm4QD1Kaj5xKQ33qjR/o/nNaj9EqK57ssp0dof5cCCd7cnTgTLNTLUQ48zJ7W8Q54JzA76F317Ai5AbwKUqo/eMwTOO1rG9aaqCYNk4bcYtxZnYKCKldI2MnBjP9QatwW33UwWjs2bSpDaF3cb/5rLVYv5oiZGzV19j2p8x7fekmKAoNRZqjXzzv15h/9oZNSnjycjpyY7gHN4JcT4hhECMM7shsBsHxig4J2ix0VRqBXWgQnCeWgvT/nXm+cBh3jMdml9/H7lyDV7C1064a+i0yU+1Q1pHyNaImFohtZJztqE6T8zTTM6ZWupilCiVNE2oCvs7d6jlBC+g3lOdBTq1VMRhQYNWanV4R+vASi61GWFh8AGthWmamePMNM1Mc6ReGw1e3B8xy6sdVl2oQnxPLfZTVm1H7MFVFSmZNM8c7txhf3bGfLanpIRWbZm2NjbmiZwzr3/dkW7fxmlFT3YMw4ACKSdiTkxDYBw8Q/CWZCuFUio5lxacCKO4psF3mNPMlCbmaaKUa6LB5iHo0e/1S/ePe5THkoJcKEXbbIIqWjIlJXKM5BhJOZnX6hw+hOXCWStaMilO+OCZp6m5YzZ/pC20W0LqUoz/mzuXUqJW85ujiOVTpgMpReYcr1ugsQYYPZoCjrNeClCXmYVt27XlFLRWtIGbDhNxjsa9BPObdydLvrnGSK2ZOh1ABB9GxHm0zQs6Z8ZLq6eWQukRXc4W/KREagFGN7YlRUrJ5JxIOV43L8Io4jzfbqYioOV2e7sXbwO1MLtm0jQzHw5MhwM5FWoV01zvLUGuNikpOSOlUFIkiWPye8I4gnMMwfxrj1ILgFK0uYs5k0shxUhuuZKe5DEqqtRSyCXzAAV+Fhx8bN3W1PU2Q8v6qasWS/OVtVRyiuSUSDE1w2Zze4hvVMECMrXakM+JFCdSjIRxoJSdTQ21uKfS05GVkjOlaXHOiVLXxE7NecmslVqvEUXAMfHKqslHMwSL97CG0J0jyYkSI/s7d5j2B6YpWoJdnGmukzVRjiLe41Bz6XLmcHaGG3eoE8ZhQOsAg0dcbZOeBlhNycLiZDSQc6Jk41vNdXmEB9g34FkADBsFPgaZnr9taMv2hOaebdOENnRboLJcR5fcQM8l9NqLnhHLKRLnmZwLThzBu3X2pBaqVgunSzGN7Z89E9hznnqcW7mXXDHAsoTGanGFNVY6WXSg4W7mMOOW40yaDszT3oyPVnBWCFKlNi0vOOdbwYnDA/hALoWSM9P+QMrK6e459BSGISBaW843oVpJcTY/OJurZi6bthnpNegpVXkQws9Ag2XV3qX3dRtvsM5K2AZt6UKtxbJYKTKnSC6V2qJDvFsiKlVlCIJ433IJFlw4tboILZkaI9PhAKrsxoBvVT9aiuWim5uWs0V0XWuVVUFQy8o9SIev3osAG87bhukxa9x1TrVhr9X80hgjMSVqFZBexuTJtfmkVQk+gFphCk7wzqNOcc6GfqmReX9AVEm3dhAcEixBVDrAVSktsLEkVO/yVhexJK7uL89Ag5sBE5r5vlf/r/zQ219yIqeJw9kZ0+FAKQricX5AQrDikWgJc1WlVPAVxLc0ZAg4Aa+VmmwuLU53QBP7k5aH2A02HVQzORcLMAqL4Vv/VkW4qDj1iiO5e7VmnQ/v2m0/Vg9Cm3HLqRm3lC3L5WQpwpM259MfvqolaqSlxkTM07BjC6hap3khxYgTcN4tRq4egdmN7NoeHkJ74ZlQhLJOhNuW+x1nNFcoKTEdJg77O8zT1KaZnBmyEIwGsIodBDKVFBMxFobB47zgvTOQnEd8RRRynlEtHPYDpZyQa0GCIqweQ63aqnnApv4tk6T3bfmxXFjhLiLvFJG/EpHPi8jnRORX2vaXROQvReTf2ueLD3E/4y/tPCZrrr23+Gj4qc0S52z+aEyUZnTE+VaSuiZvl+NLIZfSQl3LF8SYSLlYDYRYKaqi1Fra/NpMagn1WozvVS05rz3AYdNIHmzcHhpgIAO/pqrfDfwg8GER+R7go8CnVPU9wKfa7wtkNRIszVy1+ei7avNHDYA4z0yHiZQLpSrOh1av23i85R46uDFFYpqZponD4cB+OjDHSMpqAIfQZpEL037PNFlmLMdMyTZ7bEV/VkRY26dStzUrF4J8IUWo6teAr7Xvb4jI57Hi6/cD72uH/SHw18CvX3S9ulXRRVbAl5yD0tyl1Oa/ZtIcTQOdx4fQCqbdMifmnKMn0jp39vqGZYqeNkuinXNb7iFFogjO7UB9ox3ZDKdVIRZ+xsq0npofLCLfAXwv8LfAWxv4qOrXROQt9zlnqXB/7vnnl4e8t6y+sfFvbVHbTEkWripu4V9xziYkOwc7ARxDaGCqzQSrKnmJGiuqzmoh2jS9Ziso0RQpuU1yBr80aWlad8/a5rpp6/3koQEWkeeAPwV+VVVf7w91kWwr3N/y1rdqq5ZaqKwn3js5CGIzGLWSpz3xsGf/+qvMBwtt/TDY8Hbh3JoJCCFsApc2Y1dM22KxejLQpWjQO0cFsiZKSVAz0XtqqHBygnObOVlYsntbxb5IHgpgERkwcP9IVf+sbf5vEXlb0963Aa9cfKWNq7PZdLyxDetSqDmZ5qbjjJn05Qd3t7OVQBm4vYZSqxK0orgGcusY53DKWtnecx3Saef8BKhy100vkIfxIgT4A+Dzqvq7m12fAD7Yvn8Q+POHuWEpFgTU5qv2KvU+Q6woNZtrNt85I57tybNNjfu2EMUWoWjLG2tzn+rm2QWH4AAninfKLnhOgmcMw7Lew4cBHwLBjzjxlrJMmdym43NOQL98492We1hWI10gD6PBPwT8PPCPIvLZtu03gN8C/kREfgH4IvDTF11oy1fS/rPcuqzcq0qplpSJKRJzppTmPYusHdFq1Ba/rmlX1+DlPkvZas8fSHO5WMJq2fQV3SiWQhWoda2QXxvO5l5P7kX8DfcfGD9y0fnHFwNLSbIup1hITo782JQzc0zElChVW4VqX/5lc3KtgUcAr2xuxtRtDCdIixXWlGZPHhvI1nFgVCHOChNtzSVHGiubL5e1COYxxcBcNa7lcjfBRUpW82UVNJlcKqKC1EydACctCLAoawll+x30+H7SqV+6m7VpSvfKW+ejrUAxW1GiDgpOua9Rv8DYXTnA21BDmubaltWQlJa3LaWFrNh2UTN+VCuDtXLUXgrQRM8985E1tc6s5/b10dSNoiy7NzOHcjyMn6oXcTmyDNqFnLvznmJknmYLW2v3X9sZpRXnbfx73fpSbVQsUeFCnbIO5f5lE3x0EW+rRV0LZM6z4zbB8zCe6pUCvJiKe3Z/51CHcwHvA8Mw2KI/NinCjZU0ADvd6PrAC7Kyue+qgpZZ6z70coId51vlfVs2K4ux2FKQrqbjSUPlK5GGXK9TGMcdUipyOxFTpB4sq1Wbi6S6AteLAOQcwLW7Umz85WUljdtoc9/Vqi/b2hELw3075Igc6B7JtdPgvu7sWLe6CwYOQRyMw4hTpeTJ9sZkALgOXLsYamVObbLUeVOrWit+AXeLgmmj9jxD++jBhKCoWvjdPDhaZfKjxheLPBMN7g+9+MDdm2jDLQwBUZv2yb5YarG5An198WqgVu5wvl2jQOuu5V7LQN6uMGog20paM27NS1uTRVtaegy5cg52nby2FgjopkbBZiqCoyBUBMvf2rFW5dC0U1aAFV000TS6ByaGTu08Di3G29rFNUix7NvxfJs2PljGhGxb/GC5ejftLh+qaVj3g9FNarF5A+cI0wIV++6cBSh9BWi/yXmAZesPNwvZjdRS59A3VtC+nEsXNlqVH2kj6mLiuPLivx7J9Z/2UH292nE6cP0TywGgtp5ZTMNl4wmsFND/a520rDFuhSlHAYn52SUl1ukgy4xICOj5TM29yPgCCnlGXoRuGroCIKy1agu4yjJ9Y7URdmyQ9iIO7zY6qkcgKCzzaZtAbfG9a1sOa0FLo46eidu4CFtcF9/7IbQXnlGofMwSW0S2pk7Xfz2NWAultOHfXKjOzSayILmdMdu+9sDAtHN6OZRl9dzqlrVSLBHZgKsLi7SDFiP5IH/tmSyCAZrR2ERoCwf27Ev3AlpO1dliFF3ytK7Nx3WKkOUapvF9FNR+uTZLXBd+9t7j2nsh1jXP97C/LN7vxgo8nDybyh5gNT9swF0t9/oIzVtQOYrW1uQ66/E9umruVd3osZWtHZeaurZOzLUXcuDOAbdEcMd0cdy+B8tjvzftcURE/gc4A75+ZTd9fHmZh2/nu1T1zffacaUAA4jI36nq913pTR9DnlY7b95declyA/Aly7MA+GPP4J6PI0+lnVfOwf/f5IYiLlluAL5kuTKAr/PLnB9QovubIvIVEfls+/uJR772VXDwdX+Zcyv9epuqfkZEngf+HvhJ4GeAO6r624977avS4OVlzqoagf4y52shqvo1Vf1M+/4G0Et0n1iuCuB7vcz5qTzA05ZzJboAHxGRfxCRjz9sFf9Wrgrge+VGrp1/eL5EF/g94LuA92JF6L/zqNe8KoAf+WXOVy33KtFV1f9W1aJWOvT7GNU9klwVwMvLnEVkxF7m/IkruveFcr8S3Wb8uvwU8E+Peu0ryQc/7sucr1DuV6L7ARF5L0Zn/wH84qNe+CZUvmS5ieQuWW4AvmS5AfiS5QbgS5YbgC9ZbgC+ZLkB+JLlfwGFARC01R7W9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-plenty",
   "metadata": {},
   "source": [
    "## 2. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-scale",
   "metadata": {},
   "source": [
    "### 2.1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informative-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hybrid-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augment_Images(X, y):\n",
    "    \n",
    "    augmented = []\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        seed = (i, 0)\n",
    "        image = tf.cast(X[i], tf.float32)\n",
    "        image = (image / 255.0)\n",
    "        \n",
    "        flag = random.randint(0, 9)\n",
    "        \n",
    "        if (flag <= 5):\n",
    "            result = (image * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 6):\n",
    "            flip_h = tf.image.flip_left_right(image)\n",
    "            result = (flip_h * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 7):\n",
    "            flip_v = tf.image.flip_up_down(image)\n",
    "            result = (flip_v * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 8):\n",
    "            bright = tf.image.stateless_random_brightness(image, 0.1, seed)\n",
    "            result = (bright * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "        if (flag == 9):\n",
    "            contrast = tf.image.stateless_random_contrast(image, 0.9, 1.1, seed)\n",
    "            result = (contrast * 255)\n",
    "            augmented.append(result)\n",
    "            \n",
    "    augmented_nm, y = Normalize_Images(augmented, y)\n",
    "        \n",
    "    return augmented_nm, y\n",
    "\n",
    "def Normalize_Images(X, y):\n",
    "    \n",
    "    normalized = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        image = tf.cast(X[i], tf.float32)\n",
    "        image = (image - 128.0) / 128.0\n",
    "        normalized.append(image)\n",
    "    \n",
    "    return normalized, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dangerous-candle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1-0] Preprocessing Start!\n",
      "[1-1] Shuffle Done!\n",
      "[1-2] Training Data Augmented!\n",
      "[1-3] Datasets Normalized!\n",
      "[1-F] Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"[1-0] Preprocessing Start!\")\n",
    "\n",
    "# -- 2.1.1. Shuffle the datasets. -- # \n",
    "X_train_sf, y_train_sf = shuffle(X_train, y_train)\n",
    "X_valid_sf, y_valid_sf = shuffle(X_valid, y_valid)\n",
    "X_test_sf, y_test_sf = shuffle(X_test, y_test)\n",
    "print(\"[1-1] Shuffle Done!\")\n",
    "\n",
    "# -- 2.1.2. Data augmentation & normalization. -- #\n",
    "X_train_pp, y_train_pp = Augment_Images(X_train_sf, y_train_sf)\n",
    "print(\"[1-2] Training Data Augmented!\")\n",
    "\n",
    "X_train_nm, y_train_nm = Normalize_Images(X_train_sf, y_train_sf)\n",
    "X_valid_nm, y_valid_nm = Normalize_Images(X_valid_sf, y_valid_sf)\n",
    "X_test_nm, y_test_nm = Normalize_Images(X_test_sf, y_test_sf)\n",
    "print(\"[1-3] Datasets Normalized!\")\n",
    "\n",
    "print(\"[1-F] Preprocessing Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-facility",
   "metadata": {},
   "source": [
    "### 2.2. LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "major-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "leading-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet5(X):\n",
    "    \n",
    "    # - Random W & b. - # \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    epsilon = 0.001\n",
    "    \n",
    "    # - L1: Conv. Input: 32x32x3. Output: 28x28x6. - #\n",
    "    conv1_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, 3, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.add(tf.nn.conv2d(X, conv1_W, strides=[1, 1, 1, 1], padding='VALID'), conv1_b)\n",
    "    conv1   = tf.nn.relu(conv1)\n",
    "    # -- L1 Batch normalization. \n",
    "    mean_1, var_1 = v1.nn.moments(conv1, [0])\n",
    "    scale_1 = tf.Variable(tf.ones([28, 28, 6]))\n",
    "    offset_1 = tf.Variable(tf.zeros([28, 28, 6]))\n",
    "    conv1 = v1.nn.batch_normalization(conv1, mean_1, var_1, offset_1, scale_1, epsilon)\n",
    "    # -- L1 Pooling. Input: 28x28x6. Output: 14x14x6. \n",
    "    conv1   = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # - L2: Conv. Input: 14x14x6. Output: 10x10x16. - # \n",
    "    conv2_W = tf.Variable(tf.random.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.add(tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID'), conv2_b)\n",
    "    conv2   = tf.nn.relu(conv2)\n",
    "    # -- L2 Batch normalization. \n",
    "    mean_2, var_2 = v1.nn.moments(conv2, [0])\n",
    "    scale_2 = tf.Variable(tf.ones([10, 10, 16]))\n",
    "    offset_2 = tf.Variable(tf.zeros([10, 10, 16]))\n",
    "    conv2 = v1.nn.batch_normalization(conv2, mean_2, var_2, offset_2, scale_2, epsilon)\n",
    "    # -- L2 Pooling. Input: 10x10x16. Output: 5x5x16. \n",
    "    conv2   = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    # -- L2 Flatten. Input: 5x5x16. Output: 400.\n",
    "    fc0     = v1.layers.flatten(conv2)   \n",
    "    \n",
    "    # - L3: Fully connected. Input: 400. Output: 120. - #\n",
    "    fc1_W   = tf.Variable(tf.random.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b   = tf.Variable(tf.zeros(120))\n",
    "    fc1     = tf.add(tf.matmul(fc0, fc1_W), fc1_b)\n",
    "    fc1     = tf.nn.relu(fc1)\n",
    "    # -- L3. Batch normalization. \n",
    "    mean_3, var_3 = v1.nn.moments(fc1, [0])\n",
    "    scale_3 = tf.Variable(tf.ones([120]))\n",
    "    offset_3 = tf.Variable(tf.zeros([120]))\n",
    "    fc1 = v1.nn.batch_normalization(fc1, mean_3, var_3, offset_3, scale_3, epsilon)\n",
    "    # -- L3. Dropout. \n",
    "    fc1     = v1.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # - L4: Fully connected. Input: 120. Output: 84. - #\n",
    "    fc2_W   = tf.Variable(tf.random.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b   = tf.Variable(tf.zeros(84))\n",
    "    fc2     = tf.add(tf.matmul(fc1, fc2_W), fc2_b)\n",
    "    fc2     = tf.nn.relu(fc2)\n",
    "    # -- L4. Batch normalization. \n",
    "    mean_4, var_4 = v1.nn.moments(fc2, [0])\n",
    "    scale_4 = tf.Variable(tf.ones([84]))\n",
    "    offset_4 = tf.Variable(tf.zeros([84]))\n",
    "    fc2 = v1.nn.batch_normalization(fc2, mean_4, var_4, offset_4, scale_4, epsilon)\n",
    "    # -- L4. Dropout. \n",
    "    fc2     = v1.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    # - L5: Fully connected. Input: 84. Output: 43. - # \n",
    "    fc3_W   = tf.Variable(tf.random.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b   = tf.Variable(tf.zeros(43))\n",
    "    fc3     = tf.add(tf.matmul(fc2, fc3_W), fc3_b)\n",
    "    logits  = fc3\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-dover",
   "metadata": {},
   "source": [
    "### 2.3. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "controlled-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "BATCH_SIZE = 256\n",
    "ETA = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "photographic-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "D:\\MLSB\\Environment\\envs\\UDND\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "G = v1.Graph()\n",
    "\n",
    "with G.as_default():\n",
    "    \n",
    "    x = v1.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "    y = v1.placeholder(tf.int32, (None))\n",
    "    one_hot_y = v1.one_hot(y, 43)\n",
    "    keep_prob = v1.placeholder(v1.float32)\n",
    "    \n",
    "    logits = LeNet5(x)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = v1.train.AdamOptimizer(learning_rate = ETA)\n",
    "    training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    saver = v1.train.Saver()\n",
    "    \n",
    "    def Evaluate_Model(X_data, y_data):\n",
    "        \n",
    "        num_examples = len(X_data)\n",
    "        total_accuracy = 0\n",
    "        sess = v1.get_default_session()\n",
    "        \n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            \n",
    "            batch_x, batch_y = X_data[offset : offset+BATCH_SIZE], y_data[offset : offset+BATCH_SIZE]\n",
    "            accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1})\n",
    "            total_accuracy += (accuracy * len(batch_x))\n",
    "            \n",
    "        return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "therapeutic-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.751\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.855\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.890\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.890\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.903\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.899\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.922\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.921\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.929\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.927\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.918\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    sess.run(v1.global_variables_initializer())\n",
    "    num_examples = len(X_train_pp)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    v1.set_random_seed(123456)\n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        X_train, y_train = shuffle(X_train_pp, y_train_pp)\n",
    "        \n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            \n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "            \n",
    "        validation_accuracy = Evaluate_Model(X_valid_nm, y_valid_nm)\n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "metallic-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.927\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    test_accuracy = Evaluate_Model(X_test_nm, y_test_nm)\n",
    "    \n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "hindu-nomination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Validation Accuracy = 0.932\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    valid_accuracy = Evaluate_Model(X_valid_nm, y_valid_nm)\n",
    "    \n",
    "    print(\"Validation Accuracy = {:.3f}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sapphire-ridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Training Accuracy = 0.992\n"
     ]
    }
   ],
   "source": [
    "with v1.Session(graph=G) as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    train_accuracy = Evaluate_Model(X_train_nm, y_train_nm)\n",
    "    \n",
    "    print(\"Training Accuracy = {:.3f}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-bradley",
   "metadata": {},
   "source": [
    "## 3. Test Model on New Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-theme",
   "metadata": {},
   "source": [
    "### 3.1. Load and plot the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-exemption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "super-mileage",
   "metadata": {},
   "source": [
    "### 3.2. Predict the sign type for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-smile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "exciting-locator",
   "metadata": {},
   "source": [
    "### 3.3. 5 Top Softmax probabilities for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-congress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
